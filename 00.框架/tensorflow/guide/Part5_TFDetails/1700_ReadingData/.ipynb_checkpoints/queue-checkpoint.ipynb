{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queue主要包含入列（enqueue）和出列（dequeue）两个操作。enqueue操作返回计算图中的一个Operation节点，dequeue操作返回一个Tensor值。Tensor在创建时同样只是一个定义（或称为“声明”），需要放在Session中运行才能获得真正的数值。下面是一个单独使用Queue的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.InteractiveSession()\n",
    "\n",
    "q = tf.FIFOQueue(2, \"float\")\n",
    "init = q.enqueue_many(([0,0],))\n",
    "\n",
    "x = q.dequeue()\n",
    "y = x+1\n",
    "q_inc = q.enqueue([y])\n",
    "\n",
    "init.run()\n",
    "q_inc.run()\n",
    "q_inc.run()\n",
    "q_inc.run()\n",
    "x.eval()  # 返回1\n",
    "x.eval()  # 返回2\n",
    "# x.eval()  # 卡住"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果一次性入列超过Queue Size的数据，enqueue操作会卡住，直到有数据（被其他线程）从队列取出。对一个已经取空的队列使用dequeue操作也会卡住，直到有新的数据（从其他线程）写入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.QueueRunner "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow的计算主要在使用CPU/GPU和内存，而数据读取涉及磁盘操作，速度远低于前者操作。因此通常会使用多个线程读取数据，然后使用一个线程消费数据。QueueRunner就是来管理这些读写队列的线程的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QueueRunner需要与Queue一起使用（这名字已经注定了它和Queue脱不开干系），但并不一定必须使用Coordinator。看下面这个例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406.0\n",
      "525.0\n",
      "531.0\n",
      "600.0\n",
      "747.0\n",
      "938.0\n",
      "1049.0\n",
      "1154.0\n",
      "1221.0\n",
      "1254.0\n",
      "1375.0\n",
      "1402.0\n",
      "1419.0\n",
      "1439.0\n",
      "1453.0\n",
      "1472.0\n",
      "1483.0\n",
      "1491.0\n",
      "1502.0\n",
      "1607.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf  \n",
    "import sys  \n",
    "q = tf.FIFOQueue(10, \"float\")  \n",
    "counter = tf.Variable(0.0)  #计数器\n",
    "# 给计数器加一\n",
    "increment_op = tf.assign_add(counter, 1.0)\n",
    "# 将计数器加入队列\n",
    "enqueue_op = q.enqueue(counter)\n",
    "\n",
    "# 创建QueueRunner\n",
    "# 用多个线程向队列添加数据\n",
    "# 这里实际创建了4个线程，两个增加计数，两个执行入队\n",
    "qr = tf.train.QueueRunner(q, enqueue_ops=[increment_op, enqueue_op] * 2)\n",
    "\n",
    "# 主线程\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "# 启动入队线程\n",
    "qr.create_threads(sess, start=True)\n",
    "for i in range(20):\n",
    "    print (sess.run(q.dequeue()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "增加计数的进程会不停的后台运行，执行入队的进程会先执行10次（因为队列长度只有10），然后主线程开始消费数据，当一部分数据消费被后，入队的进程又会开始执行。最终主线程消费完20个数据后停止，但其他线程继续运行，程序不会结束。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Coordinator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coordinator是个用来保存线程组运行状态的协调器对象，它和TensorFlow的Queue没有必然关系，是可以单独和Python线程使用的。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "67\n",
      "\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "7\n",
      "6\n",
      "98\n",
      "\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import threading, time\n",
    "\n",
    "# 子线程函数\n",
    "def loop(coord, id):\n",
    "    t = 0\n",
    "    while not coord.should_stop():\n",
    "        print(id)\n",
    "        time.sleep(1)\n",
    "        t += 1\n",
    "        # 只有1号线程调用request_stop方法\n",
    "        if (t >= 2 and id == 3):\n",
    "            coord.request_stop()\n",
    "\n",
    "# 主线程\n",
    "coord = tf.train.Coordinator()\n",
    "# 使用Python API创建10个线程\n",
    "threads = [threading.Thread(target=loop, args=(coord, i)) for i in range(10)]\n",
    "\n",
    "# 启动所有线程，并等待线程结束\n",
    "for t in threads: t.start()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的结果中,到3号进程出现第三次的时候就停止了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将这个程序运行起来，会发现所有的子线程执行完两个周期后都会停止，主线程会等待所有子线程都停止后结束，从而使整个程序结束。由此可见，只要有任何一个线程调用了Coordinator的request_stop方法，所有的线程都可以通过should_stop方法感知并停止当前线程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将QueueRunner和Coordinator一起使用，实际上就是封装了这个判断操作，从而使任何一个现成出现异常时，能够正常结束整个程序，同时主线程也可以直接调用request_stop方法来停止所有子线程的执行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 在一起 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一种，显式的创建QueueRunner，然后调用它的create_threads方法启动线程。例如下面这段代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  [[ 8.072982   8.653856  17.27093    0.7228348]\n",
      " [ 4.608924  10.285613   3.8815064  1.795224 ]]\n",
      "label:  [1 1]\n",
      "data:  [[-0.46109232  1.8469156  -3.507136   -8.240773  ]\n",
      " [ 6.468706   -5.065259    5.394888   -4.0868597 ]]\n",
      "label:  [1 1]\n",
      "data:  [[  7.157522    11.016243     3.425578     2.6567597 ]\n",
      " [ -1.7380219   -9.55438     -0.72827405 -19.364346  ]]\n",
      "label:  [1 1]\n",
      "data:  [[-9.699322  15.753821  11.209943   5.086297 ]\n",
      " [-6.4316053  1.8453496 14.600264   1.3042086]]\n",
      "label:  [0 1]\n",
      "data:  [[ 13.971433   13.47641    -7.131435   14.155379 ]\n",
      " [-25.876547    3.8011718 -15.418064    9.784495 ]]\n",
      "label:  [1 0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 1000个4维输入向量，每个数取值为1-10之间的随机数\n",
    "data = 10 * np.random.randn(1000, 4) + 1\n",
    "# 1000个随机的目标值，值为0或1\n",
    "target = np.random.randint(0, 2, size=1000)\n",
    "\n",
    "# 创建Queue，队列中每一项包含一个输入数据和相应的目标值\n",
    "queue = tf.FIFOQueue(capacity=50, dtypes=[tf.float32, tf.int32], shapes=[[4], []])\n",
    "\n",
    "# 批量入列数据（这是一个Operation）\n",
    "enqueue_op = queue.enqueue_many([data, target])\n",
    "# 出列数据（这是一个Tensor定义）,dequeue_many(n)方法可以一次出队列多个元素\n",
    "# data_sample, label_sample = queue.dequeue()\n",
    "data_sample, label_sample = queue.dequeue_many(2)\n",
    "\n",
    "# 创建包含4个线程的QueueRunner\n",
    "qr = tf.train.QueueRunner(queue, [enqueue_op] * 4)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 创建Coordinator\n",
    "    coord = tf.train.Coordinator()\n",
    "    # 启动QueueRunner管理的线程\n",
    "    enqueue_threads = qr.create_threads(sess, coord=coord, start=True)\n",
    "    # 主线程，消费100个数据\n",
    "    for step in range(5):\n",
    "        if coord.should_stop():\n",
    "            break\n",
    "        data_batch, label_batch = sess.run([data_sample, label_sample])\n",
    "        print('data: ', data_batch)\n",
    "        print('label: ', label_batch)\n",
    "    # 主线程计算完成，停止所有采集数据的进程\n",
    "    coord.request_stop()\n",
    "    coord.join(enqueue_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二种，使用全局的start_queue_runners方法启动线程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 同时打开多个文件，显示创建Queue，同时隐含了QueueRunner的创建\n",
    "filename_queue = tf.train.string_input_producer([\"data1.csv\",\"data2.csv\"])\n",
    "reader = tf.TextLineReader(skip_header_lines=1)\n",
    "# Tensorflow的Reader对象可以直接接受一个Queue作为输入\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    # 启动计算图中所有的队列线程\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    # 主线程，消费100个数据\n",
    "    for _ in range(100):\n",
    "        features, labels = sess.run([data_batch, label_batch])\n",
    "    # 主线程计算完成，停止所有采集数据的进程\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个例子中，tf.train.string_input_produecer会将一个隐含的QueueRunner添加到全局图中（类似的操作还有tf.train.shuffle_batch等）。\n",
    "由于没有显式地返回QueueRunner来用create_threads启动线程，这里使用了tf.train.start_queue_runners方法直接启动tf.GraphKeys.QUEUE_RUNNERS集合中的所有队列线程。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
