{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Declare list of features, we only have one real-valued feature\n",
    "def model(features, labels, mode):\n",
    "    # Build a linear model and predict values\n",
    "    W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "    b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "    y = W*features['x'] + b\n",
    "    \n",
    "    # Loss sub-graph\n",
    "    loss = tf.reduce_sum(tf.square(y - labels))\n",
    "    \n",
    "    # Training sub-graph\n",
    "    global_step = tf.train.get_global_step()\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    train = tf.group(optimizer.minimize(loss), tf.assign_add(global_step, 1))\n",
    "    \n",
    "    # ModelFnOps connects subgraphs we built to the appropriate functionality.\n",
    "    return tf.contrib.learn.ModelFnOps(\n",
    "        mode=mode, predictions=y,\n",
    "        loss=loss,\n",
    "        train_op=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train the model use self-defined model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_master': '', '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_task_id': 0, '_num_worker_replicas': 0, '_task_type': None, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_model_dir': './output2', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001CB62D24320>, '_is_chief': True, '_session_config': None, '_evaluation_master': '', '_tf_random_seed': None, '_environment': 'local'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./output2\\model.ckpt-2000\n",
      "INFO:tensorflow:Saving checkpoints for 2001 into ./output2\\model.ckpt.\n",
      "INFO:tensorflow:step = 2001, loss = 9.69708056604e-23\n",
      "INFO:tensorflow:global_step/sec: 991.662\n",
      "INFO:tensorflow:step = 2101, loss = 1.42217622875e-23 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1014.04\n",
      "INFO:tensorflow:step = 2201, loss = 2.54860183085e-24 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 1092.51\n",
      "INFO:tensorflow:step = 2301, loss = 3.11008325602e-25 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1003.72\n",
      "INFO:tensorflow:step = 2401, loss = 2.65818761447e-26 (0.100 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2500 into ./output2\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.66035499026e-27.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-20-02:40:27\n",
      "INFO:tensorflow:Restoring parameters from ./output2\\model.ckpt-2500\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-20-02:40:28\n",
      "INFO:tensorflow:Saving dict for global step 2500: global_step = 2500, loss = 1.26924e-27\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-20-02:40:28\n",
      "INFO:tensorflow:Restoring parameters from ./output2\\model.ckpt-2500\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-20-02:40:29\n",
      "INFO:tensorflow:Saving dict for global step 2500: global_step = 2500, loss = 0.0101\n",
      "train loss: {'loss': 1.2692403e-27, 'global_step': 2500}\n",
      "eval loss: {'loss': 0.010100016, 'global_step': 2500}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.contrib.learn.Estimator(model_fn=model, model_dir='./output2')\n",
    "\n",
    "# define our data sets\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_train}, y_train, 4, num_epochs=1000)\n",
    "# eval_input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_eval}, y_eval, 4, num_epochs=1000)\n",
    "\n",
    "# train\n",
    "estimator.fit(input_fn=input_fn, steps=1000)\n",
    "\n",
    "# Here we evaluate how well our model did.\n",
    "train_loss = estimator.evaluate(input_fn=input_fn)\n",
    "# eval_loss = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train loss: %r\"% train_loss)\n",
    "# print(\"eval loss: %r\"% eval_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
